{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "941a4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import AsyncHTMLSession, HTMLSession\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adad2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('site_urls.json', 'r') as f:\n",
    "    urls = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3559aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.leopalace21.com/en/search/chintai/area'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls['urls'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a17280fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ccab66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_detail_checkpoint = \"checkpoint_property_details_link.json\"\n",
    "\n",
    "properties_links_pages_filename = \"checkpoint_properties_links_pages.json\"\n",
    "\n",
    "properties_links_pages_filename = \"properties_links_pages.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4dd5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scrapper():\n",
    "    def __init__(self, url):\n",
    "        self.domain = 'https://www.leopalace21.com'\n",
    "        self.url = url\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "        }\n",
    "        self.session = session\n",
    "        self.html = self.session.get(self.url, headers=self.headers, timeout=10) # take html from the site\n",
    "        self.soup = BeautifulSoup(self.html.content, 'html.parser') # parse html with BeautifulSoup\n",
    "    \n",
    "    def change_url(self, new_url): # change url\n",
    "        self.url = new_url\n",
    "        self.html = self.session.get(self.url, headers=self.headers, timeout=10) # take html from the site\n",
    "        self.soup = BeautifulSoup(self.html.content, 'html.parser') # parse html with BeautifulSoup\n",
    "        \n",
    "    def print_html(self): # print formatted html\n",
    "        print(self.soup.prettify())\n",
    "        \n",
    "    def print_data(self): # print non html\n",
    "        for x in self.soup:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27330791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_element(soup, tag, class_name): # first matching element\n",
    "        if class_name is None:\n",
    "            return soup.find(tag)\n",
    "        return soup.find(tag, class_=class_name)\n",
    "        \n",
    "def target_element_all(soup, tag, class_name): # all matching elements\n",
    "    if class_name is None:\n",
    "        return soup.find_all(tag)\n",
    "    return soup.find_all(tag, class_=class_name)\n",
    "\n",
    "def target_element_css(soup, css_selector): # css selector\n",
    "    return soup.select_one(css_selector)\n",
    "    \n",
    "def target_element_text(soup): # search by text\n",
    "    return [data.get_text() for data in soup]\n",
    "\n",
    "def retry_with_backoff(attempt): # retry after failed connection\n",
    "    wait_time = min(60, (2 ** attempt) + random.uniform(0, 1))\n",
    "    time.sleep(wait_time)\n",
    "    \n",
    "def save_json(urls, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump({'urls': urls}, f, indent=4)\n",
    "        \n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f).get(\"urls\", 0)\n",
    "    \n",
    "def checkpoint_save(index, filename): # save data incrementally\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump({\"index\": index}, f)\n",
    "        \n",
    "def checkpoint_load(filename): # load data incrementally\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f).get(\"index\", 0)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "    \n",
    "def save_to_excel(data):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28a5d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_property_details_link(url, index, total_pages): # scrape property details from property page\n",
    "    \n",
    "    #progress checkpoint\n",
    "    mod = total_pages / 5 # 20% of progress\n",
    "    if index % mod == 0 and index != 0:\n",
    "        checkpoint_save(index, property_detail_checkpoint)\n",
    "    \n",
    "    r = scrapper(url)\n",
    "    property_info_page = list(target_element_all(r.soup, 'a', 'RoomItem_link__RoXCn'))\n",
    "    filtered_links = [item for item in property_info_page if not re.search(r\"\\bmonthly\\b\", item['href'], re.IGNORECASE)]\n",
    "    \n",
    "    if len(filtered_links) == 1:\n",
    "        return fetch_all_detail(r.domain + filtered_links[0]['href'])\n",
    "    else:\n",
    "        chunk = []\n",
    "        for link in filtered_links:\n",
    "            chunk.extend(fetch_all_detail(r.domain + link['href']))\n",
    "        return chunk\n",
    "    \n",
    "def fetch_property_link(base_url, page_num, domain): # scrape property links from listing page\n",
    "    url = f\"{base_url}{page_num}\"\n",
    "    try:\n",
    "        r = scrapper(url)\n",
    "        soup = target_element_all(r.soup, 'a', 'ApartmentItemDetails_apartment-item-details__pn2sc ApartmentItemDetails_-responsive__ZRuEF')\n",
    "        time.sleep(random.uniform(0.5, 2))  # sleep between 0.5 to 2 seconds\n",
    "        return [domain + link['href'] for link in soup]\n",
    "    except Exception as e:\n",
    "        retry_with_backoff(3)\n",
    "        return []\n",
    "    \n",
    "def fetch_all_detail(url):\n",
    "    r = scrapper(url)\n",
    "    chunk = []\n",
    "    try:\n",
    "        chunk.append({\"property name\": target_element(r.soup, 'h1', 'page_heading__9lqpn').get_text()})\n",
    "        chunk.append({\"price\": target_element(r.soup, 'span', 'Price_price__6qQfX').get_text().replace(',', '')})\n",
    "        chunk.append({\"maintanence\": re.sub(r\"[^0-9]\", \"\", target_element(r.soup, 'span', 'Price_expenses__2meeQ').get_text().replace(',', ''))})\n",
    "        chunk.append({\"gmap\": target_element(r.soup, 'a', 'page_map-link__v6STN')['href']})\n",
    "        \n",
    "        brokerage_fee = target_element_all(r.soup, 'span', 'RequiredRentCost_text__QVPh6')\n",
    "        brokerage_fee = target_element_text(brokerage_fee)\n",
    "        # in order: brokerage fee, scecurity deposit/deposit, non-refundable restoration fee, key money\n",
    "        \n",
    "        chunk.append({\"brokerage fee\":brokerage_fee[0]})\n",
    "        chunk.append({\"scecurity deposit/deposit\":brokerage_fee[1]})\n",
    "        chunk.append({\"non-refundable restoration fee\":brokerage_fee[2]})\n",
    "        chunk.append({\"key money\":brokerage_fee[3]})\n",
    "        \n",
    "        match = re.search(r\"/properties/chintai/([^/]+)/([^/]+)/\", r.url)\n",
    "        if match:\n",
    "            prefecture = match.group(1)\n",
    "            city = match.group(2)\n",
    "            \n",
    "            # remove post code\n",
    "            city = re.sub(r'-\\d+$', '', city)\n",
    "        chunk.append({\"prefecture\": prefecture})\n",
    "        chunk.append({\"city\": city})\n",
    "        \n",
    "        details = target_element_all(r.soup, 'div', 'TitleTextItem_title-text-item__3dJO_')\n",
    "        for detail in details:\n",
    "    \n",
    "            name = target_element( detail,'p', 'TitleTextItem_title__kkVCx')\n",
    "            value = target_element(detail, 'span', 'TitleTextItem_text__4vy_f')\n",
    "            if value == None:\n",
    "                continue\n",
    "            chunk.append({name.get_text(): value.get_text()})\n",
    "        \n",
    "        time.sleep(random.uniform(0.5, 2))  # sleep between 0.5 to 2 seconds\n",
    "        return chunk\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        retry_with_backoff(3)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c419ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = scrapper(urls['urls'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149aab0",
   "metadata": {},
   "source": [
    "Getting Prefecture Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6af1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler.soup = target_element_css(crawler.soup, 'div.FooterMiscInternalLinkContainer_content__M1tIW div.FooterMiscInternalLinkTextLink_text-link-container__2u2zd')\n",
    "crawler.soup = target_element_all(crawler.soup, 'a', 'TextLink_text-link__Z6GQ4 TextLink_-white__uwMVe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41b0f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefectures = target_element_text(crawler.soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "978b8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefecture_url = []\n",
    "for i, prefecture in enumerate(prefectures):\n",
    "    prefecture_url.append(urls['urls'][1].replace(\"PREFECTURE\", prefecture.lower())) # attaching prefecture to base url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29e091",
   "metadata": {},
   "source": [
    "Getting Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2a3bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing https://www.leopalace21.com/en/properties/chintai/area/okinawa?page= with ['12'] pages: 100%|██████████| 47/47 [00:48<00:00,  1.03s/it]   \n"
     ]
    }
   ],
   "source": [
    "properties_links_pages = []\n",
    "    \n",
    "if os.path.exists(properties_links_pages_filename):\n",
    "    choice = input(f\"{properties_links_pages_filename} File Detected, Use the File? (Y/n): \").strip().lower()\n",
    "    if choice == \"\" or choice == \"y\":\n",
    "        property_links = load_json(properties_links_pages_filename)\n",
    "else:\n",
    "    \n",
    "    with tqdm(prefecture_url) as pbar:\n",
    "        for prefecture in pbar:\n",
    "            crawler.change_url(prefecture) # change url to url with prefecture\n",
    "            page_number = target_element_all(crawler.soup, 'a', 'Pager_link__rnYFP')[:-1] # excluding the last element which is \"next page\"\n",
    "            page_number =target_element_text(page_number)[len(page_number)-1:]\n",
    "            \n",
    "            pbar.set_description(f\"Processing {prefecture} with {page_number} pages\")\n",
    "            \n",
    "            result = {\"link\": prefecture, \"page_number\": page_number[0]}\n",
    "            properties_links_pages.append(result)\n",
    "            \n",
    "    save_json(properties_links_pages, properties_links_pages_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9999f4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'link': 'https://www.leopalace21.com/en/properties/chintai/area/hokkaido?page=',\n",
       "  'page_number': '129'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/aomori?page=',\n",
       "  'page_number': '48'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/iwate?page=',\n",
       "  'page_number': '38'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/miyagi?page=',\n",
       "  'page_number': '126'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/akita?page=',\n",
       "  'page_number': '21'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/yamagata?page=',\n",
       "  'page_number': '53'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/fukushima?page=',\n",
       "  'page_number': '113'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/tokyo?page=',\n",
       "  'page_number': '154'},\n",
       " {'link': 'https://www.leopalace21.com/en/properties/chintai/area/kanagawa?page=',\n",
       "  'page_number': '250'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties_links_pages[:len(properties_links_pages)//5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6566b1",
   "metadata": {},
   "source": [
    "Getting Property Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35bc3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prefectures: 100%|██████████| 47/47 [18:13<00:00, 23.27s/it]\n"
     ]
    }
   ],
   "source": [
    "property_links = []\n",
    "\n",
    "for link in tqdm(properties_links_pages, desc=\"Processing prefectures\"):\n",
    "    total_pages = int(link['page_number'])\n",
    "    page_range = range(1, total_pages + 1)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(fetch_property_link, link['link'], page, crawler.domain) for page in page_range]\n",
    "        for future in tqdm(as_completed(futures), total=total_pages, desc=\"Pages\", leave=False):\n",
    "            property_links.extend(future.result())\n",
    "\n",
    "property_links = list(dict.fromkeys(property_links))\n",
    "\n",
    "save_json(property_links, \"property_urls.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777326a",
   "metadata": {},
   "source": [
    "Property Details Hell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8832b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25966"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(property_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7420e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Properties:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "json_result = []\n",
    "property_links = property_links[:1000]\n",
    "\n",
    "if os.path.exists(property_detail_checkpoint):\n",
    "    choice = input(\"Checkpoint File Detected, Use the File? (Y/n): \").strip().lower()\n",
    "    if choice == \"\" or choice == \"y\":\n",
    "        property_links = property_links[checkpoint_load(property_detail_checkpoint):]\n",
    "        \n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(fetch_all_property_details_link, link, idx, len(property_links)): (idx, link) for idx, link in enumerate(property_links)}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Properties\", leave=False):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result:  # Check if result is not empty\n",
    "                json_result.extend(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {futures[future]}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3650826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218146"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2941a43",
   "metadata": {},
   "source": [
    "Outputing as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5fdd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "current_row = {}\n",
    "for item in json_result:\n",
    "    for key, value in item.items():\n",
    "        if key == 'property name' and 'property name' in current_row:\n",
    "            # property name is already added -> push the old row and start new\n",
    "            rows.append(current_row)\n",
    "            current_row = {}\n",
    "        current_row[key] = value\n",
    "if current_row:\n",
    "    rows.append(current_row)\n",
    "    \n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bcd175bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4042 entries, 0 to 4041\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   property name                                       4042 non-null   object\n",
      " 1   price                                               4042 non-null   object\n",
      " 2   maintanence                                         4042 non-null   object\n",
      " 3   gmap                                                4042 non-null   object\n",
      " 4   brokerage fee                                       4042 non-null   object\n",
      " 5   scecurity deposit/deposit                           4042 non-null   object\n",
      " 6   non-refundable restoration fee                      4042 non-null   object\n",
      " 7   key money                                           4042 non-null   object\n",
      " 8   prefecture                                          4042 non-null   object\n",
      " 9   city                                                4042 non-null   object\n",
      " 10  Bathroom · Toilet                                   4042 non-null   object\n",
      " 11  Security                                            4009 non-null   object\n",
      " 12  Broadcasting・Communication                          4014 non-null   object\n",
      " 13  Others                                              4042 non-null   object\n",
      " 14  Address                                             4042 non-null   object\n",
      " 15  Commute                                             4042 non-null   object\n",
      " 16  Floor plan/Area size                                4042 non-null   object\n",
      " 17  Home Furniture・Home appliances                      4042 non-null   object\n",
      " 18  Building structure                                  4042 non-null   object\n",
      " 19  Floor/Number of Floors                              4042 non-null   object\n",
      " 20  Total units                                         4042 non-null   object\n",
      " 21  Monthly parking lot                                 4042 non-null   object\n",
      " 22  fire insurance                                      4042 non-null   object\n",
      " 23  Transaction type                                    4042 non-null   object\n",
      " 24  Current condition                                   4042 non-null   object\n",
      " 25  Type/Building age                                   4042 non-null   object\n",
      " 26  Moving in/Hand-over                                 4042 non-null   object\n",
      " 27  Depreciation・Non-refundable Restoration Fee         4042 non-null   object\n",
      " 28  Other                                               4042 non-null   object\n",
      " 29  Renewal fee                                         4042 non-null   object\n",
      " 30  Community fee                                       4042 non-null   object\n",
      " 31  Key exchange fee/Smartlock system registration fee  4042 non-null   object\n",
      " 32  Cleaning fee when moving out                        4042 non-null   object\n",
      " 33  Antibacterial cleaning fee（Optional）                4042 non-null   object\n",
      " 34  Tenant support system plus（Optional）                4042 non-null   object\n",
      " 35  Guarantee commission fee（Individual contract only）  4042 non-null   object\n",
      " 36  Internet usage fee                                  4042 non-null   object\n",
      " 37  Name                                                4042 non-null   object\n",
      " 38  Location                                            4042 non-null   object\n",
      " 39  Business Hours                                      4042 non-null   object\n",
      " 40  License number                                      4042 non-null   object\n",
      " 41  Affiliated organization                             4042 non-null   object\n",
      "dtypes: object(42)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34f6d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"df.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
